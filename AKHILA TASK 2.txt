#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
get_ipython().run_line_magic('matplotlib', 'inline')


# In[2]:


iris =pd.read_csv("C:/Users/akhila bodasu/Downloads/Iris.csv")


# In[3]:


iris


# In[4]:


iris.info()


# In[5]:


iris.describe()


# In[6]:


iris.info()


# In[7]:


iris.drop(['Id','Species'],axis=1)


# In[8]:


#EXPLORATORY ANALYSIS


# In[9]:


sns.pairplot(iris)


# In[10]:


x=iris.iloc[:,[0,1,2,3]].values


# In[11]:


#finding the optimum no of clusters for k means classification


# In[12]:


from sklearn.cluster import KMeans
wcss = []
for i in range(1,12):
    kmeans=KMeans(n_clusters=i,init='k-means++',max_iter=300,random_state=0,algorithm='auto')
    kmeans=kmeans.fit(x)
    wcss.append(kmeans.inertia_)


# In[13]:


# PLOTTING RESULS ON GRAPH
 


# In[14]:


plt.plot(range(1,12),wcss)
plt.title("the elbow curve method")
plt.xlabel("the number of clusters")
plt.ylabel('wcss')
plt.show()





# In[15]:


#APPLY KMAENS TO THE DATASET


# In[16]:


kmeans=KMeans(n_clusters=3,init='k-means++', n_init=10, max_iter=300,verbose=0, random_state=None, algorithm='auto')
y_kmeans = kmeans.fit_predict(x)


# In[17]:


y_kmeans


# In[18]:


#visulizing the clusters


# In[19]:


plt.scatter(x[y_kmeans == 0,0],x[y_kmeans== 0,1], s=100, c='yellow',label='iris-setosa')
plt.scatter(x[y_kmeans == 1,0],x[y_kmeans== 1,1], s=100, c='pink',label='iris-versicolour')
plt.scatter(x[y_kmeans == 2,0],x[y_kmeans== 2,1], s=100, c='blue',label='iris-virginica')

plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s=100, c='red', label='centroids')
plt.legend()




 




# In[ ]:





# In[ ]:





# In[ ]:





